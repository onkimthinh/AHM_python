{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network():\n",
    "    def __init__(self, NN_structure, alpha, max_iter):\n",
    "        self.NN_structure = NN_structure\n",
    "        self.n_layers = len(NN_structure)\n",
    "        self.alpha = alpha\n",
    "        self.max_iter = max_iter\n",
    "    \n",
    "    # Defind some types of activation functions and its derivatives:\n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def d_sigmoid(self,x):\n",
    "        return self.sigmoid(x)*(1-self.sigmoid(x))\n",
    "    \n",
    "    def linear(self,x):\n",
    "        return x\n",
    "    \n",
    "    def d_linear(self,x):\n",
    "        return 1\n",
    "\n",
    "    def relu(self,x):\n",
    "        return np.maximum(0,x)\n",
    "\n",
    "    def d_relu(self,x):\n",
    "        dx = np.where(x <= 0, 0, 1)\n",
    "        return dx\n",
    "\n",
    "    def tanh(self,x):\n",
    "        return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "\n",
    "    def d_tanh(self,x):\n",
    "        return 1 - self.tanh(x)**2\n",
    "    \n",
    "    \n",
    "    # Initialize weights:\n",
    "    def init_weights(self, seed):\n",
    "        np.random.seed(seed)\n",
    "        self.theta_ = {}\n",
    "        for L in range(1, self.n_layers):\n",
    "#             self.theta_['Layer' + str(L+1)] = np.ones((self.NN_structure[L]['n_neurons'], \\\n",
    "#                                                         self.NN_structure[L-1]['n_neurons'] + 1)) * 0.2\n",
    "            self.theta_['Layer' + str(L+1)] = np.random.randn(self.NN_structure[L]['n_neurons'], \\\n",
    "                                                        self.NN_structure[L-1]['n_neurons'] + 1) * 0.1\n",
    "        return self.theta_\n",
    "    \n",
    "\n",
    "    def add_bias(self, Xi):\n",
    "        Xi = np.concatenate(([1], Xi))\n",
    "        return Xi\n",
    "    \n",
    "    def copy_column(self, Xi, n):\n",
    "        Ai = Xi.T\n",
    "        for _ in range(n-1):\n",
    "            Ai = np.concatenate((Ai, Xi.T), axis = 1)\n",
    "        return Ai\n",
    "    \n",
    "    def forward_propagation(self, Xi):\n",
    "        self.z_ = {}\n",
    "        self.a_ = {}\n",
    "        self.z_['2'] = np.dot(self.theta_['Layer2'], self.add_bias(Xi).T)\n",
    "        self.a_['2'] = eval('self.'+self.NN_structure[1]['activ_func'])(self.z_['2'])\n",
    "        \n",
    "        for L in range (2, self.n_layers):\n",
    "            self.a_[str(L)] = self.add_bias(self.a_[str(L)])\n",
    "            self.z_[str(L+1)] = np.dot(self.theta_['Layer'+str(L+1)],self.a_[str(L)])\n",
    "            self.a_[str(L+1)] = eval('self.'+self.NN_structure[L]['activ_func'])(self.z_[str(L+1)])\n",
    "        return self\n",
    "            \n",
    "    def fit(self, X, y):    # including training and validation\n",
    "        self.init_weights(seed = 10)\n",
    "        self.costs = []\n",
    "        self.R_sq_record = []\n",
    "        n_train = math.ceil(0.9 * X.shape[0])\n",
    "        n_validate = X.shape[0] - n_train\n",
    "        \n",
    "        X_train = X[0 : n_train]\n",
    "        y_train = y[0 : n_train]\n",
    "        X_validate = X[n_train : X.shape[0]]\n",
    "        y_validate = y[n_train : X.shape[0]]\n",
    "        \n",
    "        self.n_iter = 0\n",
    "        for _ in range(self.max_iter):\n",
    "            cost = 0\n",
    "            for i in range(X_train.shape[0]):\n",
    "                self.delta = {}\n",
    "                self.update = {}\n",
    "\n",
    "                self.forward_propagation(X_train[i])\n",
    "                self.delta[str(self.n_layers)] = self.a_[str(self.n_layers)] - y_train[i]\n",
    "                delta_copy = self.copy_column(np.array([self.delta[str(self.n_layers)]]), \\\n",
    "                                              self.NN_structure[self.n_layers-2]['n_neurons'] + 1)\n",
    "\n",
    "                self.update[str(self.n_layers)] = np.multiply(self.a_[str(self.n_layers-1)], delta_copy)\n",
    "\n",
    "                cost += ((self.a_[str(self.n_layers)]-y_train[i])**2/2/X_train.shape[0]).sum()\n",
    "                \n",
    "                self.a_['1'] = self.add_bias(X_train[i])\n",
    "                for L in range(self.n_layers-1, 1, -1):\n",
    "                    theta_back = np.delete(self.theta_['Layer'+str(L+1)], 0, 1)\n",
    "                    self.delta[str(L)] = np.multiply(np.dot(theta_back.T, self.delta[str(L+1)]), \\\n",
    "                        eval('self.d_' + self.NN_structure[L-1]['activ_func'])(self.z_[str(L)]))\n",
    "                    delta_copy = self.copy_column(np.array([self.delta[str(L)]]), \\\n",
    "                                              self.NN_structure[L-2]['n_neurons'] + 1)\n",
    "                    self.update[str(L)] = np.multiply(self.a_[str(L-1)], delta_copy)\n",
    "\n",
    "                for L in range(2, self.n_layers+1):\n",
    "                    self.theta_['Layer'+str(L)] -= self.alpha * self.update[str(L)]\n",
    "                        \n",
    "            \n",
    "            sum_theta_sq = 0\n",
    "            for L in range(2, self.n_layers + 1):\n",
    "                sum_theta_sq += np.square(self.theta_['Layer'+str(L)]).sum()\n",
    "            \n",
    "            # Validation step:\n",
    "            SS_res = 0\n",
    "            for j in range(X_validate.shape[0]):\n",
    "                self.forward_propagation(X_validate[j])\n",
    "                error_each_sample = ((self.a_[str(self.n_layers)] - y_validate[j])**2).sum()\n",
    "                SS_res += error_each_sample\n",
    "#             y_bar = y_validate.mean(0)\n",
    "#             SS_total = ((y_validate - y_bar)**2).sum()\n",
    "            SS_total = (y_validate**2).sum()\n",
    "            R_sq = (1 - SS_res/ SS_total)\n",
    "            if R_sq >= 0.9:\n",
    "                break\n",
    "            self.n_iter += 1\n",
    "            self.R_sq_record.append(R_sq)\n",
    "            self.costs.append(cost)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_excel('Input_AHM.xlsx')\n",
    "target = pd.read_excel('Output_AHM.xlsx')\n",
    "field_data = pd.read_excel('Field_data.xlsx')\n",
    "y_merge = np.concatenate((target, field_data), axis = 0)\n",
    "y_merge = np.log(y_merge)\n",
    "\n",
    "np.random.seed(101)\n",
    "input_data, target = shuffle(input_data, target)\n",
    "\n",
    "n_train = math.ceil(0.90 * input_data.shape[0])           # 90% data for training and validation\n",
    "n_test = input_data.shape[0] - n_train                    # the rest for blind testing\n",
    "\n",
    "X = input_data.values\n",
    "y = target.values\n",
    "y = np.log(y)\n",
    "field_data = field_data.values\n",
    "\n",
    "def normalize(X):\n",
    "    A = X.copy()\n",
    "    mean = X.mean(axis = 0)\n",
    "    diff = X.max(axis = 0) - X.min(axis = 0)\n",
    "    for j in range(0, X.shape[1]):  \n",
    "        A[:,j] = (X[:,j] - mean[j]) / diff[j]\n",
    "    return A\n",
    "\n",
    "def denormalize(X_norm, mean_X, diff_X):\n",
    "    X_denorm = X_norm.copy()\n",
    "    for j in range(X_norm.shape[0]):  \n",
    "        X_denorm[j] = X_norm[j] * diff_X[j] + mean_X[j]\n",
    "    return X_denorm\n",
    "\n",
    "mean_X = X.mean(axis = 0)\n",
    "mean_y = y.mean(axis = 0)\n",
    "diff_X = X.max(axis = 0) - X.min(axis = 0)\n",
    "diff_y = y.max(axis = 0) - y.min(axis = 0)\n",
    "\n",
    "# Normalization:\n",
    "X_norm = normalize(X)\n",
    "y_norm = normalize(y)\n",
    "\n",
    "# Define ranges of parameters:\n",
    "bound_min = X_norm.min(axis = 0)\n",
    "bound_max = X_norm.max(axis = 0)\n",
    "diff = np.fabs(bound_max - bound_min)\n",
    "bounds = []\n",
    "for i in range(bound_min.shape[0]):\n",
    "    bounds.append((bound_min[i], bound_max[i]))\n",
    "\n",
    "# Normalize the field oil production:\n",
    "y_merge_norm = normalize(y_merge)\n",
    "field_data_norm = y_merge_norm[-1]\n",
    "\n",
    "# Split the dataset:\n",
    "X_train = X_norm[0 : n_train]\n",
    "y_train = y_norm[0 : n_train]\n",
    "X_test = X_norm[n_train : input_data.shape[0]]\n",
    "y_test = y_norm[n_train : input_data.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case 0: BEST case\n",
    "NN_structure = [{'n_neurons' : 15, 'activ_func' : 'none'},   \n",
    "                {'n_neurons' : 45, 'activ_func' : 'tanh'},\n",
    "                {'n_neurons' : 80, 'activ_func' : 'tanh'},\n",
    "                {'n_neurons' : 50, 'activ_func' : 'linear'}]       \n",
    "\n",
    "ANN = Neural_Network(NN_structure, alpha = 0.008, max_iter = 500) \n",
    "\n",
    "ANN.fit(X_train, y_train)\n",
    "\n",
    "if ANN.n_iter < ANN.max_iter:\n",
    "    plt.plot(range(1, ANN.n_iter + 2), ANN.costs)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Cost value')\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.plot(range(1, ANN.n_iter + 1), ANN.costs)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Cost value')\n",
    "    plt.show()\n",
    "\n",
    "plt.plot(range(1, ANN.n_iter + 1), ANN.R_sq_record)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('R squared value')\n",
    "plt.show()\n",
    "\n",
    "# Blind testing:\n",
    "SS_res = 0\n",
    "y_predict = np.array([])\n",
    "for i in range(n_test):\n",
    "    ANN.forward_propagation(X_test[i])\n",
    "    y_predict = np.concatenate((y_predict, ANN.a_[str(ANN.n_layers)]), axis = 0)\n",
    "    error_each_sample = ((ANN.a_[str(ANN.n_layers)] - y_test[i])**2).sum()\n",
    "    SS_res += error_each_sample\n",
    "y_predict = y_predict.reshape(y_test.shape)\n",
    "\n",
    "y_bar = y_test.mean(0)\n",
    "print(SS_res)\n",
    "SS_total = ((y_test - y_bar)**2).sum()\n",
    "# SS_total = (y_test**2).sum()\n",
    "R_sq = (1 - abs(SS_res)/ SS_total)\n",
    "print(R_sq)\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    y_test_denorm = denormalize(y_test[i, :], mean_y, diff_y)\n",
    "    y_predict_denorm = denormalize(y_predict[i, :], mean_y, diff_y)\n",
    "    y_test_bar = y_test_denorm.mean(0)\n",
    "    SS_res_1 = ((np.exp(y_test_denorm) - np.exp(y_predict_denorm))**2).sum()\n",
    "    SS_total_1 = (np.exp(y_test_denorm)**2).sum()\n",
    "    R_sq_1 = (1 - abs(SS_res_1)/ SS_total_1)\n",
    "    print('Accuracy = ', R_sq_1)\n",
    "    plt.plot(range(1, 51), np.exp(y_test_denorm))\n",
    "    plt.plot(range(1, 51), np.exp(y_predict_denorm))\n",
    "    plt.legend(['Target','Predict'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test case 1:\n",
    "NN_structure = [{'n_neurons' : 15, 'activ_func' : 'none'},   \n",
    "                {'n_neurons' : 40, 'activ_func' : 'sigmoid'},\n",
    "                {'n_neurons' : 50, 'activ_func' : 'linear'}]       \n",
    "\n",
    "ANN = Neural_Network(NN_structure, alpha = 0.008, max_iter = 500)\n",
    "\n",
    "ANN.fit(X_train, y_train)\n",
    "\n",
    "if ANN.n_iter < ANN.max_iter:\n",
    "    plt.plot(range(1, ANN.n_iter + 1), ANN.costs)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Cost value')\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.plot(range(1, ANN.n_iter + 1), ANN.costs)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Cost value')\n",
    "    plt.show()\n",
    "\n",
    "plt.plot(range(1, ANN.n_iter + 1), ANN.R_sq_record)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('R squared value')\n",
    "plt.show()\n",
    "\n",
    "# Blind testing:\n",
    "SS_res = 0\n",
    "y_predict = np.array([])\n",
    "for i in range(n_test):\n",
    "    ANN.forward_propagation(X_test[i])\n",
    "    y_predict = np.concatenate((y_predict, ANN.a_[str(ANN.n_layers)]), axis = 0)\n",
    "    error_each_sample = ((ANN.a_[str(ANN.n_layers)] - y_test[i])**2).sum()\n",
    "    SS_res += error_each_sample\n",
    "y_predict = y_predict.reshape(y_test.shape)\n",
    "\n",
    "y_bar = y_test.mean(0)\n",
    "print(SS_res)\n",
    "SS_total = ((y_test - y_bar)**2).sum()\n",
    "# SS_total = (y_test**2).sum()\n",
    "R_sq = (1 - abs(SS_res)/ SS_total)\n",
    "print(R_sq)\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    y_test_denorm = denormalize(y_test[i, :], mean_y, diff_y)\n",
    "    y_predict_denorm = denormalize(y_predict[i, :], mean_y, diff_y)\n",
    "    y_test_bar = y_test_denorm.mean(0)\n",
    "    SS_res_1 = ((np.exp(y_test_denorm) - np.exp(y_predict_denorm))**2).sum()\n",
    "    SS_total_1 = ((np.exp(y_test_denorm))**2).sum()\n",
    "    R_sq_1 = (1 - abs(SS_res_1)/ SS_total_1)\n",
    "    print('Accuracy = ', R_sq_1)\n",
    "    plt.plot(range(1, 51), np.exp(y_test_denorm))\n",
    "    plt.plot(range(1, 51), np.exp(y_predict_denorm))\n",
    "    plt.legend(['Target','Predict'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test case 2: (second best)\n",
    "NN_structure = [{'n_neurons' : 15, 'activ_func' : 'none'},   \n",
    "                {'n_neurons' : 45, 'activ_func' : 'tanh'},\n",
    "                {'n_neurons' : 80, 'activ_func' : 'tanh'},\n",
    "                {'n_neurons' : 50, 'activ_func' : 'linear'}]       \n",
    "\n",
    "ANN = Neural_Network(NN_structure, alpha = 0.01, max_iter = 500)\n",
    "\n",
    "ANN.fit(X_train, y_train)\n",
    "\n",
    "if ANN.n_iter < ANN.max_iter:\n",
    "    plt.plot(range(1, ANN.n_iter + 2), ANN.costs)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Cost value')\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.plot(range(1, ANN.n_iter + 1), ANN.costs)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Cost value')\n",
    "    plt.show()\n",
    "\n",
    "plt.plot(range(1, ANN.n_iter + 1), ANN.R_sq_record)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('R squared value')\n",
    "plt.show()\n",
    "\n",
    "# Blind testing:\n",
    "SS_res = 0\n",
    "y_predict = np.array([])\n",
    "for i in range(n_test):\n",
    "    ANN.forward_propagation(X_test[i])\n",
    "    y_predict = np.concatenate((y_predict, ANN.a_[str(ANN.n_layers)]), axis = 0)\n",
    "    error_each_sample = ((ANN.a_[str(ANN.n_layers)] - y_test[i])**2).sum()\n",
    "    SS_res += error_each_sample\n",
    "y_predict = y_predict.reshape(y_test.shape)\n",
    "\n",
    "y_bar = y_test.mean(0)\n",
    "print(SS_res)\n",
    "SS_total = ((y_test - y_bar)**2).sum()\n",
    "# SS_total = (y_test**2).sum()\n",
    "R_sq = (1 - abs(SS_res)/ SS_total)\n",
    "print(R_sq)\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    y_test_denorm = denormalize(y_test[i, :], mean_y, diff_y)\n",
    "    y_predict_denorm = denormalize(y_predict[i, :], mean_y, diff_y)\n",
    "    y_test_bar = y_test_denorm.mean(0)\n",
    "    SS_res_1 = ((np.exp(y_test_denorm) - np.exp(y_predict_denorm))**2).sum()\n",
    "    SS_total_1 = ((np.exp(y_test_denorm))**2).sum()\n",
    "    R_sq_1 = (1 - abs(SS_res_1)/ SS_total_1)\n",
    "    print('Accuracy = ', R_sq_1)\n",
    "    plt.plot(range(1, 51), np.exp(y_test_denorm))\n",
    "    plt.plot(range(1, 51), np.exp(y_predict_denorm))\n",
    "    plt.legend(['Target','Predict'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test case 3: (third best)\n",
    "NN_structure = [{'n_neurons' : 15, 'activ_func' : 'none'},\n",
    "                {'n_neurons' : 100, 'activ_func' : 'relu'},\n",
    "                {'n_neurons' : 120, 'activ_func' : 'relu'},\n",
    "                {'n_neurons' : 160, 'activ_func' : 'relu'},\n",
    "                {'n_neurons' : 50, 'activ_func' : 'linear'}]       \n",
    "\n",
    "ANN = Neural_Network(NN_structure, alpha = 0.01, max_iter = 500)\n",
    "\n",
    "ANN.fit(X_train, y_train)\n",
    "\n",
    "if ANN.n_iter < ANN.max_iter:\n",
    "    plt.plot(range(1, ANN.n_iter + 2), ANN.costs)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Cost value')\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.plot(range(1, ANN.n_iter + 1), ANN.costs)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Cost value')\n",
    "    plt.show()\n",
    "\n",
    "plt.plot(range(1, ANN.n_iter + 1), ANN.R_sq_record)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('R squared value')\n",
    "plt.show()\n",
    "\n",
    "# Blind testing:\n",
    "SS_res = 0\n",
    "y_predict = np.array([])\n",
    "for i in range(n_test):\n",
    "    ANN.forward_propagation(X_test[i])\n",
    "    y_predict = np.concatenate((y_predict, ANN.a_[str(ANN.n_layers)]), axis = 0)\n",
    "    error_each_sample = ((ANN.a_[str(ANN.n_layers)] - y_test[i])**2).sum()\n",
    "    SS_res += error_each_sample\n",
    "y_predict = y_predict.reshape(y_test.shape)\n",
    "\n",
    "y_bar = y_test.mean(0)\n",
    "print(SS_res)\n",
    "SS_total = ((y_test - y_bar)**2).sum()\n",
    "# SS_total = (y_test**2).sum()\n",
    "R_sq = (1 - abs(SS_res)/ SS_total)\n",
    "print(R_sq)\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    y_test_denorm = denormalize(y_test[i, :], mean_y, diff_y)\n",
    "    y_predict_denorm = denormalize(y_predict[i, :], mean_y, diff_y)\n",
    "    y_test_bar = y_test_denorm.mean(0)\n",
    "    SS_res_1 = ((np.exp(y_test_denorm) - np.exp(y_predict_denorm))**2).sum()\n",
    "    SS_total_1 = ((np.exp(y_test_denorm))**2).sum()\n",
    "    R_sq_1 = (1 - abs(SS_res_1)/ SS_total_1)\n",
    "    print('Accuracy = ', R_sq_1)\n",
    "    plt.plot(range(1, 51), np.exp(y_test_denorm))\n",
    "    plt.plot(range(1, 51), np.exp(y_predict_denorm))\n",
    "    plt.legend(['Target','Predict'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case 4:\n",
    "NN_structure = [{'n_neurons' : 15, 'activ_func' : 'none'},   \n",
    "                {'n_neurons' : 90, 'activ_func' : 'sigmoid'},\n",
    "                {'n_neurons' : 150, 'activ_func' : 'relu'},\n",
    "                {'n_neurons' : 50, 'activ_func' : 'linear'}]       \n",
    "\n",
    "ANN = Neural_Network(NN_structure, alpha = 0.01, max_iter = 500)\n",
    "\n",
    "ANN.fit(X_train, y_train)\n",
    "\n",
    "if ANN.n_iter < ANN.max_iter:\n",
    "    plt.plot(range(1, ANN.n_iter + 2), ANN.costs)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Cost value')\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.plot(range(1, ANN.n_iter + 1), ANN.costs)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Cost value')\n",
    "    plt.show()\n",
    "\n",
    "plt.plot(range(1, ANN.n_iter + 1), ANN.R_sq_record)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('R squared value')\n",
    "plt.show()\n",
    "\n",
    "# Blind testing:\n",
    "SS_res = 0\n",
    "y_predict = np.array([])\n",
    "for i in range(n_test):\n",
    "    ANN.forward_propagation(X_test[i])\n",
    "    y_predict = np.concatenate((y_predict, ANN.a_[str(ANN.n_layers)]), axis = 0)\n",
    "    error_each_sample = ((ANN.a_[str(ANN.n_layers)] - y_test[i])**2).sum()\n",
    "    SS_res += error_each_sample\n",
    "y_predict = y_predict.reshape(y_test.shape)\n",
    "\n",
    "y_bar = y_test.mean(0)\n",
    "print(SS_res)\n",
    "SS_total = ((y_test - y_bar)**2).sum()\n",
    "# SS_total = (y_test**2).sum()\n",
    "R_sq = (1 - abs(SS_res)/ SS_total)\n",
    "print(R_sq)\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    y_test_denorm = denormalize(y_test[i, :], mean_y, diff_y)\n",
    "    y_predict_denorm = denormalize(y_predict[i, :], mean_y, diff_y)\n",
    "    y_test_bar = y_test_denorm.mean(0)\n",
    "    SS_res_1 = ((np.exp(y_test_denorm) - np.exp(y_predict_denorm))**2).sum()\n",
    "    SS_total_1 = ((np.exp(y_test_denorm))**2).sum()\n",
    "    R_sq_1 = (1 - abs(SS_res_1)/ SS_total_1)\n",
    "    print('Accuracy = ', R_sq_1)\n",
    "    plt.plot(range(1, 51), np.exp(y_test_denorm))\n",
    "    plt.plot(range(1, 51), np.exp(y_predict_denorm))\n",
    "    plt.legend(['Target','Predict'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test case 5: a good case\n",
    "NN_structure = [{'n_neurons' : 15, 'activ_func' : 'none'},   \n",
    "                {'n_neurons' : 90, 'activ_func' : 'sigmoid'},\n",
    "                {'n_neurons' : 180, 'activ_func' : 'relu'},\n",
    "                {'n_neurons' : 50, 'activ_func' : 'linear'}]       \n",
    "\n",
    "ANN = Neural_Network(NN_structure, alpha = 0.009, max_iter = 500)\n",
    "\n",
    "ANN.fit(X_train, y_train)\n",
    "\n",
    "if ANN.n_iter < ANN.max_iter:\n",
    "    plt.plot(range(1, ANN.n_iter + 1), ANN.costs)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Cost value')\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.plot(range(1, ANN.n_iter + 1), ANN.costs)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Cost value')\n",
    "    plt.show()\n",
    "\n",
    "plt.plot(range(1, ANN.n_iter + 1), ANN.R_sq_record)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('R squared value')\n",
    "plt.show()\n",
    "\n",
    "# Blind testing:\n",
    "SS_res = 0\n",
    "y_predict = np.array([])\n",
    "for i in range(n_test):\n",
    "    ANN.forward_propagation(X_test[i])\n",
    "    y_predict = np.concatenate((y_predict, ANN.a_[str(ANN.n_layers)]), axis = 0)\n",
    "    error_each_sample = ((ANN.a_[str(ANN.n_layers)] - y_test[i])**2).sum()\n",
    "    SS_res += error_each_sample\n",
    "y_predict = y_predict.reshape(y_test.shape)\n",
    "\n",
    "y_bar = y_test.mean(0)\n",
    "print(SS_res)\n",
    "SS_total = ((y_test - y_bar)**2).sum()\n",
    "# SS_total = (y_test**2).sum()\n",
    "R_sq = (1 - abs(SS_res)/ SS_total)\n",
    "print(R_sq)\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    y_test_denorm = denormalize(y_test[i, :], mean_y, diff_y)\n",
    "    y_predict_denorm = denormalize(y_predict[i, :], mean_y, diff_y)\n",
    "    y_test_bar = y_test_denorm.mean(0)\n",
    "    SS_res_1 = ((np.exp(y_test_denorm) - np.exp(y_predict_denorm))**2).sum()\n",
    "    SS_total_1 = ((np.exp(y_test_denorm))**2).sum()\n",
    "    R_sq_1 = (1 - abs(SS_res_1)/ SS_total_1)\n",
    "    print('Accuracy = ', R_sq_1)\n",
    "    plt.plot(range(1, 51), np.exp(y_test_denorm))\n",
    "    plt.plot(range(1, 51), np.exp(y_predict_denorm))\n",
    "    plt.legend(['Target','Predict'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case 7: a good case\n",
    "NN_structure = [{'n_neurons' : 15, 'activ_func' : 'none'},   \n",
    "                {'n_neurons' : 45, 'activ_func' : 'tanh'},\n",
    "                {'n_neurons' : 80, 'activ_func' : 'sigmoid'},\n",
    "                {'n_neurons' : 180, 'activ_func' : 'relu'},\n",
    "                {'n_neurons' : 50, 'activ_func' : 'linear'}]       \n",
    "\n",
    "ANN = Neural_Network(NN_structure, alpha = 0.008, max_iter = 500) \n",
    "\n",
    "ANN.fit(X_train, y_train)\n",
    "\n",
    "if ANN.n_iter < ANN.max_iter:\n",
    "    plt.plot(range(1, ANN.n_iter + 1), ANN.costs)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Cost value')\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.plot(range(1, ANN.n_iter + 1), ANN.costs)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Cost value')\n",
    "    plt.show()\n",
    "\n",
    "plt.plot(range(1, ANN.n_iter + 1), ANN.R_sq_record)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('R squared value')\n",
    "plt.show()\n",
    "\n",
    "# Blind testing:\n",
    "SS_res = 0\n",
    "y_predict = np.array([])\n",
    "for i in range(n_test):\n",
    "    ANN.forward_propagation(X_test[i])\n",
    "    y_predict = np.concatenate((y_predict, ANN.a_[str(ANN.n_layers)]), axis = 0)\n",
    "    error_each_sample = ((ANN.a_[str(ANN.n_layers)] - y_test[i])**2).sum()\n",
    "    SS_res += error_each_sample\n",
    "y_predict = y_predict.reshape(y_test.shape)\n",
    "\n",
    "y_bar = y_test.mean(0)\n",
    "print(SS_res)\n",
    "SS_total = ((y_test - y_bar)**2).sum()\n",
    "# SS_total = (y_test**2).sum()\n",
    "R_sq = (1 - abs(SS_res)/ SS_total)\n",
    "print(R_sq)\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    y_test_denorm = denormalize(y_test[i, :], mean_y, diff_y)\n",
    "    y_predict_denorm = denormalize(y_predict[i, :], mean_y, diff_y)\n",
    "    y_test_bar = y_test_denorm.mean(0)\n",
    "    SS_res_1 = ((np.exp(y_test_denorm) - np.exp(y_predict_denorm))**2).sum()\n",
    "    SS_total_1 = ((np.exp(y_test_denorm))**2).sum()\n",
    "    R_sq_1 = (1 - abs(SS_res_1)/ SS_total_1)\n",
    "    print('Accuracy = ', R_sq_1)\n",
    "    plt.plot(range(1, 51), np.exp(y_test_denorm))\n",
    "    plt.plot(range(1, 51), np.exp(y_predict_denorm))\n",
    "    plt.legend(['Target','Predict'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
